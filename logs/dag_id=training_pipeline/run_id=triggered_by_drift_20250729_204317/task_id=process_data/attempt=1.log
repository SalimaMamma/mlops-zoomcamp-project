[2025-07-29T20:48:22.731+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-29T20:48:22.772+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: training_pipeline.process_data triggered_by_drift_20250729_204317 [queued]>
[2025-07-29T20:48:22.784+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: training_pipeline.process_data triggered_by_drift_20250729_204317 [queued]>
[2025-07-29T20:48:22.817+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 4
[2025-07-29T20:48:22.837+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): process_data> on 2025-07-29 20:43:17+00:00
[2025-07-29T20:48:22.857+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'training_pipeline', 'process_data', 'triggered_by_drift_20250729_204317', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/training_pipeline.py', '--cfg-path', '/tmp/tmpliah9yhg']
[2025-07-29T20:48:22.863+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask process_data
[2025-07-29T20:48:22.866+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=11306) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-07-29T20:48:22.867+0000] {standard_task_runner.py:63} INFO - Started process 11382 to run task
[2025-07-29T20:48:22.888+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-29T20:48:22.934+0000] {task_command.py:426} INFO - Running <TaskInstance: training_pipeline.process_data triggered_by_drift_20250729_204317 [running]> on host d78ad09e75e4
[2025-07-29T20:48:23.067+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='mlops_team@example.com' AIRFLOW_CTX_DAG_OWNER='mlops' AIRFLOW_CTX_DAG_ID='training_pipeline' AIRFLOW_CTX_TASK_ID='process_data' AIRFLOW_CTX_EXECUTION_DATE='2025-07-29T20:43:17+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='triggered_by_drift_20250729_204317'
[2025-07-29T20:48:23.069+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-29T20:48:23.160+0000] {data_processing.py:40} INFO - Loaded 11560 records from S3: data/historical_BTC_USD_20250328000000.csv
[2025-07-29T20:48:23.193+0000] {data_processing.py:40} INFO - Loaded 8669 records from S3: data/historical_BTC_USD_20250729180000.csv
[2025-07-29T20:48:23.252+0000] {data_processing.py:40} INFO - Loaded 8669 records from S3: data/historical_BTC_USD_20250729190000.csv
[2025-07-29T20:48:23.267+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729195030.csv
[2025-07-29T20:48:23.296+0000] {data_processing.py:40} INFO - Loaded 8640 records from S3: data/historical_BTC_USD_20250729195705.csv
[2025-07-29T20:48:23.328+0000] {data_processing.py:40} INFO - Loaded 8640 records from S3: data/historical_BTC_USD_20250729200813.csv
[2025-07-29T20:48:23.344+0000] {logging_mixin.py:188} WARNING - /opt/***/src/data_processing.py:39 UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
[2025-07-29T20:48:23.346+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729202101.csv
[2025-07-29T20:48:23.360+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729202646.csv
[2025-07-29T20:48:23.375+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729202706.csv
[2025-07-29T20:48:23.390+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729202727.csv
[2025-07-29T20:48:23.406+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729202748.csv
[2025-07-29T20:48:23.420+0000] {data_processing.py:40} INFO - Loaded 287 records from S3: data/historical_BTC_USD_20250729203009.csv
[2025-07-29T20:48:23.434+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729203104.csv
[2025-07-29T20:48:23.448+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729203305.csv
[2025-07-29T20:48:23.463+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729204321.csv
[2025-07-29T20:48:23.478+0000] {data_processing.py:40} INFO - Loaded 288 records from S3: data/historical_BTC_USD_20250729204818.csv
[2025-07-29T20:48:23.491+0000] {data_processing.py:84} INFO - Combined 20195 records for BTC-USD
[2025-07-29T20:48:23.938+0000] {data_processing.py:162} INFO - Removed 50 rows with NaN values. Final shape: (20145, 84)
[2025-07-29T20:48:23.951+0000] {logging_mixin.py:188} WARNING - /opt/***/src/data_processing.py:230 FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
[2025-07-29T20:48:24.201+0000] {logging_mixin.py:188} WARNING - /opt/***/src/data_processing.py:177 FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
[2025-07-29T20:48:24.222+0000] {data_processing.py:179} INFO - Prepared features: (20145, 80), Target: (20145,)
[2025-07-29T20:48:24.223+0000] {data_processing.py:180} INFO - Feature columns: 80
[2025-07-29T20:48:24.269+0000] {data_processing.py:202} INFO - Saved preprocessor to S3: s3://crypto-mlops-bucket/models/preprocessors/scaler_BTC_USD.pickle
[2025-07-29T20:48:24.275+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-29T20:48:24.276+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-29T20:48:24.288+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=training_pipeline, task_id=process_data, execution_date=20250729T204317, start_date=20250729T204822, end_date=20250729T204824
[2025-07-29T20:48:24.376+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-29T20:48:24.407+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-29T20:48:24.411+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
